{"cells":[{"cell_type":"markdown","source":["# Robert K Burns \n### DSC650 Assignment 5.2\n### Winter Quarter 2019-2020\n\nCreating a small data warehouse."],"metadata":{}},{"cell_type":"code","source":["# Importing SQL package\nfrom pyspark.sql import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Dropping any tables I may have already created in earlier rounds of testing\nspark.sql('DROP TABLE IF EXISTS elem')\nspark.sql('DROP TABLE IF EXISTS places')\nspark.sql('DROP TABLE IF EXISTS second')\nspark.sql('DROP TABLE IF EXISTS unified')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: DataFrame[]</div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Set warehouse directory\nwarehouse_dir = '/home/rkburns/spark-warehouse/'\nspark = SparkSession.builder \\\n    .appName(\"DSC650Assignment5\") \\\n    .config(\"spark.sql.warehouse.dir\", warehouse_dir) \\\n    .getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Setting file paths\ncsv_file_path1 = '/FileStore/tables/2017/elementary_schools.csv'\ncsv_file_path2 = '/FileStore/tables/2018/elementary_schools.csv'\n\ncsv_file_path3 = '/FileStore/tables/2017/places.csv'\ncsv_file_path4 = '/FileStore/tables/2018/places.csv'\n\ncsv_file_path5 = '/FileStore/tables/2017/secondary_schools.csv'\ncsv_file_path6 = '/FileStore/tables/2018/secondary_schools.csv'\n\ncsv_file_path7 = '/FileStore/tables/2017/unified_school_districts.csv'\ncsv_file_path8 = '/FileStore/tables/2018/unified_school_districts.csv'\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Load dfs and create tables (I'm sure there's a better way, I just couldn't get any to work)\ndf1 = spark.read.load(\n  csv_file_path1,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\n\ndf2 = spark.read.load(\n  csv_file_path2,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\n\ndf3 = spark.read.load(\n  csv_file_path3,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\ndf4 = spark.read.load(\n  csv_file_path4,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\ndf5 = spark.read.load(\n  csv_file_path5,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\ndf6 = spark.read.load(\n  csv_file_path6,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\ndf7 = spark.read.load(\n  csv_file_path7,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\ndf8 = spark.read.load(\n  csv_file_path8,\n  format='csv',\n  sep=',',\n  inferSchema=True,\n  header=True\n)\n\n\nelem = df1.unionAll(df2)\nelem.write.saveAsTable('elem')\n\nplaces = df3.unionAll(df4)\nplaces.write.saveAsTable('places')\n\nsecond = df5.unionAll(df6)\nsecond.write.saveAsTable('second')\n\nunified = df7.unionAll(df8)\nunified.write.saveAsTable('unified')\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Showing the count of the combined \"places\" table\nsqlContext.sql(\"SELECT COUNT(*) FROM places\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+\ncount(1)|\n+--------+\n   59151|\n+--------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["display(spark.sql(\"SELECT a.state as State, a.year as Year, a.cnt Elementary, b.cnt Secondary, c.cnt Unified \\\n                   FROM (SELECT state, year, count(*) as cnt \\\n                         FROM elementary \\\n                         WHERE state IN('NE','IA') \\\n                         GROUP BY state, year) a \\\n                   LEFT OUTER JOIN \\\n                        (SELECT state, year, count(*) as cnt \\\n                         FROM secondary \\\n                         WHERE state IN('NE','IA') \\\n                         GROUP BY state, year) b \\\n                   CROSS JOIN \\\n                         (SELECT state, year, count(*) as cnt \\\n                         FROM unified \\\n                         WHERE state IN('NE','IA') \\\n                         GROUP BY state, year) c \\\n                    ON a.state = b.state \\\n                    AND a.year = b.year \\\n                    ORDER BY a.state, a.year\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>State</th><th>Year</th><th>Elementary</th><th>Secondary</th><th>Unified</th></tr></thead><tbody><tr><td>IA</td><td>2017</td><td>336</td><td>336</td><td>333</td></tr><tr><td>IA</td><td>2017</td><td>336</td><td>336</td><td>246</td></tr><tr><td>IA</td><td>2017</td><td>336</td><td>336</td><td>336</td></tr><tr><td>IA</td><td>2017</td><td>336</td><td>336</td><td>251</td></tr><tr><td>IA</td><td>2018</td><td>333</td><td>333</td><td>246</td></tr><tr><td>IA</td><td>2018</td><td>333</td><td>333</td><td>333</td></tr><tr><td>IA</td><td>2018</td><td>333</td><td>333</td><td>336</td></tr><tr><td>IA</td><td>2018</td><td>333</td><td>333</td><td>251</td></tr><tr><td>NE</td><td>2017</td><td>251</td><td>251</td><td>251</td></tr><tr><td>NE</td><td>2017</td><td>251</td><td>251</td><td>333</td></tr><tr><td>NE</td><td>2017</td><td>251</td><td>251</td><td>246</td></tr><tr><td>NE</td><td>2017</td><td>251</td><td>251</td><td>336</td></tr><tr><td>NE</td><td>2018</td><td>246</td><td>246</td><td>333</td></tr><tr><td>NE</td><td>2018</td><td>246</td><td>246</td><td>251</td></tr><tr><td>NE</td><td>2018</td><td>246</td><td>246</td><td>246</td></tr><tr><td>NE</td><td>2018</td><td>246</td><td>246</td><td>336</td></tr></tbody></table></div>"]}}],"execution_count":8},{"cell_type":"code","source":["## Second part of the exercise: Recreate the report from Assignment 4.2 using SQL"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Dropping any tables I may have created during testing\nspark.sql('DROP TABLE IF EXISTS flights')\nspark.sql('DROP TABLE IF EXISTS airport_codes')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: DataFrame[]</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# import data\ndf_flights = spark.read.parquet(\"/FileStore/tables/flights.parquet\")\ndf_airport_codes = spark.read.load(\"/FileStore/tables/airport_codes-e62ed.csv\",\n  format=\"csv\",\n  sep=\",\",\n  inferSchema=True,\n  header=True\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["df_flights.write.saveAsTable('flights')\ndf_airport_codes.write.saveAsTable('airport_codes')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["display(spark.sql('''SELECT RANK() OVER (ORDER BY subtable.total_passengers DESC) as `Rank`, a.name as `Airport Name`, a.iata_code as `IATA Code`, \n            subtable.total_passengers as `Total Passengers`, INT(subtable.daily_passengers) as `Daily Passengers`, subtable.total_flights as `Total Flights`, \n            INT(subtable.daily_flights)  as `Daily Flights` FROM airport_codes a\n            INNER JOIN\n            (SELECT f.destination_airport_code as dest_code, SUM(f.passengers) as total_passengers, SUM(f.passengers)/365 as daily_passengers, SUM(f.flights) as total_flights, SUM(f.flights)/365 as daily_flights\n            FROM flights f\n            LEFT OUTER JOIN airport_codes d ON d.iata_code = f.destination_airport_code\n            WHERE f.flight_year = 2008\n            GROUP BY f.destination_airport_code) subtable\n            ON a.iata_code = subtable.dest_code\n            ORDER BY total_passengers DESC\n            LIMIT 10\n            '''))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Rank</th><th>Airport Name</th><th>IATA Code</th><th>Total Passengers</th><th>Daily Passengers</th><th>Total Flights</th><th>Daily Flights</th></tr></thead><tbody><tr><td>1</td><td>Hartsfield Jackson Atlanta International Airport</td><td>ATL</td><td>35561795</td><td>97429</td><td>395192</td><td>1082</td></tr><tr><td>2</td><td>Chicago O'Hare International Airport</td><td>ORD</td><td>26398793</td><td>72325</td><td>356570</td><td>976</td></tr><tr><td>3</td><td>Dallas Fort Worth International Airport</td><td>DFW</td><td>22883558</td><td>62694</td><td>270243</td><td>740</td></tr><tr><td>4</td><td>Los Angeles International Airport</td><td>LAX</td><td>19741782</td><td>54087</td><td>215000</td><td>589</td></tr><tr><td>5</td><td>McCarran International Airport</td><td>LAS</td><td>18262263</td><td>50033</td><td>164123</td><td>449</td></tr><tr><td>6</td><td>Phoenix Sky Harbor International Airport</td><td>PHX</td><td>17305718</td><td>47412</td><td>181259</td><td>496</td></tr><tr><td>7</td><td>Charlotte Douglas International Airport</td><td>CLT</td><td>15038489</td><td>41201</td><td>205040</td><td>561</td></tr><tr><td>8</td><td>George Bush Intercontinental Houston Airport</td><td>IAH</td><td>14870717</td><td>40741</td><td>214245</td><td>586</td></tr><tr><td>9</td><td>Orlando International Airport</td><td>MCO</td><td>14581086</td><td>39948</td><td>131710</td><td>360</td></tr><tr><td>10</td><td>Detroit Metropolitan Wayne County Airport</td><td>DTW</td><td>14228887</td><td>38983</td><td>191910</td><td>525</td></tr></tbody></table></div>"]}}],"execution_count":13}],"metadata":{"name":"Burns_Assignment_5_2","notebookId":3897350914755288},"nbformat":4,"nbformat_minor":0}
